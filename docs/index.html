<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>🚀 OS Research Lab - A Journey into Kernels & Code!</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <nav class="main-nav">
      <a href="#home">🏠 Home</a> |
      <a href="#cpu">⚙️ CPU Scheduling</a> |
      <a href="#memory">🧠 Memory Magic</a> |
      <a href="#jordyos">✨ jordyOS</a>
    </nav>

    <div class="content-wrapper">
        <section id="home">
            <h1>🚀 Welcome to the OS Research Lab!</h1>

            <p>Hey there, fellow tech explorer! 👋 I'm thrilled to share my journey into the fascinating world of kernel-level operating system design. This lab is all about tinkering with simulations, dabbling in machine learning, and even taking the first exciting steps toward building a custom OS from scratch. We'll be looking at schedulers, memory management, and more!</p>

            <p>This is an <strong>ongoing adventure in research and learning</strong> 🤓, where I get to explore fundamental OS concepts, try out new ideas, and (fingers crossed! 🤞) eventually bring a simple, custom operating system to life. Join me!</p>

            <hr>

            <h2>🤔 So, Why Does This Lab Exist?</h2>

            <p>Ever felt like the deepest, most interesting parts of an OS are locked away in the kernel, with textbooks offering a view but no playground? That's exactly how I felt! This repository is my personal hands-on lab to:</p>
            <ul>
                <li>🧪 Simulate and test core OS concepts <em>before</em> diving into the nitty-gritty of bare-metal C/Assembly.</li>
                <li>🤖 Explore the exciting frontier where <strong>traditional kernel logic meets machine learning</strong>. Can AI make our OS smarter?</li>
                <li>🛠️ Gradually, piece by piece, build towards a minimal, bootable operating system. It's a marathon, not a sprint!</li>
            </ul>

            <hr>

            <h2>🌟 Focus Areas Overview</h2>
            <p>Curious about what's cooking in the lab? Here's a peek at the main projects and explorations you'll find on this page:</p>
            <ul>
                <li><a href="#cpu">⚙️ CPU Scheduling Simulations: Who gets the CPU next?</a></li>
                <li><a href="#memory">🧠 Memory Management Experiments: Making the most of RAM!</a></li>
                <li>💡 ML in the Kernel Concepts: Can we teach an old OS new tricks?</li>
                <li><a href="#jordyos">✨ jordyOS (WIP Custom OS): My very own operating system!</a></li>
            </ul>

            <hr>

            <h2>📁 Directory Structure (A Quick Map!)</h2>
            <p>The website files you're looking at now are neatly tucked into the <code>/docs</code> folder. The actual heart of the project – all the cool code and experiments – lives at the repository root:</p>
            <pre><code>cpu/        🧠 # Scheduling simulations & ML-enhanced RR
memory/     💾 # Page replacement experiments (LRU, ML, etc.)
jordyOS/    💻 # Bootable toy operating system with a calculator shell!
docs/       🌐 # Static website files (Hi, you're here! 👋)
...         🛠️ # Other project files & magic</code></pre>
        </section>

        <section id="cpu">
            <h2>⚙️ CPU Scheduling Research: The Art of Juggling Tasks!</h2>

            <p>CPU scheduling is like being an air traffic controller for your computer's tasks! 🚦 It decides which program gets to use the CPU and for how long. Here, I'm simulating various strategies, both classic and cutting-edge:</p>
            <ul>
                <li><strong>Round-Robin:</strong> Taking turns, nice and simple!</li>
                <li><strong>CFS (Linux’s Completely Fair Scheduler):</strong> The gold standard for fairness in Linux.</li>
                <li><strong>ML-augmented RR:</strong> Can we use a little machine learning magic 🔮 to predict the shortest jobs or adjust time slices dynamically? Let's find out!</li>
            </ul>

            <hr>

            <h3>🤖 ML-Augmented CPU Scheduling: RR vs CFS - The Showdown!</h3>

            <p>After playing with ML for memory management (more on that later!), I thought: </p>
            <blockquote>"What if we brought machine learning into the CPU scheduler's decision-making process?" 🤔</blockquote>

            <p>So, I whipped up a Python simulation and threw two classic types of workloads at it. The goal? To see how an ML-enhanced Round-Robin scheduler stacks up against Linux's own CFS. Game on! 🎮</p>

            <h3>🔥 Workloads: Putting Schedulers to the Test</h3>
            <ul>
                <li><strong>Bursty 💨:</strong> Imagine lots of tiny, quick tasks (90%) mixed with a few long, thoughtful ones (10%).</li>
                <li><strong>Heavy-tail 🐘:</strong> Thousands of short jobs, but then BAM! A few absolutely massive, super-long tasks.</li>
            </ul>

            <h3>🏆 Schedulers Compared: Meet the Contenders</h3>
            <table>
              <thead>
                <tr>
                  <th>Scheduler</th>
                  <th>Description</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><strong>CFS</strong></td>
                  <td>Linux's default hero! It tries to be super fair by picking the task that's had the least CPU time so far. It even cleverly shrinks time slices if the queue gets long.</td>
                </tr>
                <tr>
                  <td><strong>Round-Robin (RR)</strong></td>
                  <td>The classic "take a number" system. First-in, first-out, with everyone getting a fixed time slice. (I tested with q = 5, 10, and 20).</td>
                </tr>
                <tr>
                  <td><strong>RR + ML</strong></td>
                  <td>Round-Robin, but with a smart assistant! 🧐 It uses an online classifier to try and bump tasks that are likely to finish quickly to the front of the line.</td>
                </tr>
                <tr>
                  <td><strong>RR + 2×ML</strong></td>
                  <td>This one's got two ML helpers! 🚀 One classifier (like above) AND a regressor that tries to predict how long a task will run, adjusting its time quantum on the fly (from 2 to 20 ms).</td>
                </tr>
              </tbody>
            </table>

            <h3>📊 Results: And the Winner Is...</h3>

            <h4>Bursty Workload (Lower is Better - we want fast turnarounds!)</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/cpu/images/cpu1.png" alt="Bursty Workload Scheduler Comparison">

            <h4>Heavy Workload (Lower is Better)</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/cpu/images/cpu2.png" alt="Heavy Workload Scheduler Comparison">

            <h4>Bursty Workload — RR vs 2 x ML (A closer look!)</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/cpu/images/cpu3.png" alt="Bursty Workload RR vs 2xML Comparison">

            <h4>Heavy Workload — RR vs 2 x ML (Zooming in!)</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/cpu/images/cpu4.png" alt="Heavy Workload RR vs 2xML Comparison">

            <h3>🎯 Takeaways: What Did We Learn?</h3>

            <h4>For the Bursty Workload:</h4>
            <ul>
                <li>🎉 <strong>CFS for the win!</strong> It had the lowest average and best tail latency. Fairness really does pay off here.</li>
                <li>👍 <strong>RR + ML showed promise!</strong> It improved turnaround by giving priority to those short, snappy tasks.</li>
                <li>👎 <strong>RR + 2×ML... not so much.</strong> It got a bit too eager with context switches when it mispredicted large scans, and performance actually dropped. Oops!</li>
            </ul>

            <h4>For the Heavy Workload:</h4>
            <ul>
                <li>🚀 <strong>RR + ML was a star!</strong> It managed to shave off a cool <strong>10–15%</strong> in average turnaround time (since 95% of jobs fit neatly into one slice).</li>
                <li>✨ <strong>RR + 2×ML added a tiny bit more improvement (around 3%)</strong>, but still struggled with those monster-sized jobs.</li>
                <li>🐢 <strong>CFS came in third.</strong> Its insistence on fairness, even for super-long tasks, held it back a bit in this scenario.</li>
            </ul>

            <h3>🎓 Final Lessons from the CPU Scheduling Arena</h3>
            <ul>
                <li>💡 <strong>CFS’s <code>vruntime</code> is pure genius!</strong> It achieves something close to Shortest Job First (SJF) performance but without the risk of starvation. So clever!</li>
                <li>🎯 <strong>ML shines when short tasks are the name of the game</strong> (think API gateways or GPU micro-batching).</li>
                <li>🤔 <strong>ML-based quantum tuning? Looks awesome on paper, but...</strong> it often <strong>costs more than it saves</strong> in reality due to:
                  <ul>
                      <li>More context switches (like quick changes of focus).</li>
                      <li>More knobs to tune (complexity!).</li>
                      <li>Harder to debug when things go sideways.</li>
                  </ul>
                </li>
            </ul>
            <blockquote>Also, a friendly reminder: Classic Round-Robin doesn't protect against starvation and can be easily exploited. <br>🛡️ <strong>CFS is incredibly well-designed — a truly solid default choice!</strong></blockquote>
        </section>

        <section id="memory">
            <h2>🧠 Memory Management Research: Playing Tetris with RAM!</h2>

            <p>Memory management is all about making the best use of your computer's RAM. When it's full, the OS has to decide which "page" of memory to kick out (evict) to make room for new ones. It's a tricky balancing act! ⚖️ I'm experimenting with different eviction policies:</p>
            <ul>
                <li>Classics like LRU (Least Recently Used), FIFO (First-In, First-Out), and Random (just pick one, why not? 🤷).</li>
                <li>And, you guessed it, a Machine Learning-enhanced LRU!</li>
            </ul>

            <hr>

            <h3>🤖 ML-Augmented LRU vs. The Classics: A Page-Eviction Battle!</h3>

            <p>While wrestling with virtual memory systems, a thought sparked: </p>
            <blockquote>"Could a lightweight machine learning model actually be better at deciding which pages to evict than good old LRU?" 🧐</blockquote>

            <p>With ML being all the rage, it felt like a natural step to see if we could make smarter page eviction choices based on past access patterns. So, this simulation pits four classic cache replacement policies against each other!</p>

            <h3>📜 Policies Tested: The Lineup</h3>
            <ul>
                <li><strong>LRU (Least Recently Used):</strong> The trusty OS heuristic – if you haven't been used in a while, you're probably not needed soon.</li>
                <li><strong>FIFO (First-In, First-Out):</strong> Simple and fair – the oldest page gets the boot.</li>
                <li><strong>Random:</strong> Feeling lucky? 🎲 Just evict a page at random.</li>
                <li><strong>ML Model 🧠:</strong> A logistic regression model trained to predict if a page will be reused soon. It looks at:
                  <ul>
                      <li>Long-term frequency (how often has this page been popular?).</li>
                      <li>Recent recency (was it used very recently?).</li>
                  </ul>
                </li>
            </ul>

            <h3>🛠️ Simulation Setup: The Ground Rules</h3>
            <ul>
                <li><strong>Trace size:</strong> A whopping 1,000,000 memory accesses! 📈</li>
                <li><strong>Cache sizes:</strong> Testing with 64, 128, 256, and 512 entries (think of these as different amounts of "fast memory").</li>
                <li><strong>Metric:</strong> Counting up the total cache hits (good!) and misses (boo, page fault!).</li>
            </ul>

            <h3>📊 Results: Let's See Those Charts!</h3>

            <h4>Cache Size: 64 (Tiny Cache!)</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/memory/images/Figure_1.png" alt="Cache Size 64 Comparison">

            <h4>Cache Size: 128</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/memory/images/Figure_2.png" alt="Cache Size 128 Comparison">

            <h4>Cache Size: 256</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/memory/images/Figure_3.png" alt="Cache Size 256 Comparison">

            <h4>Cache Size: 512 (More Roomy Cache)</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/memory/images/Figure_4.png" alt="Cache Size 512 Comparison">

            <h4>Hit Rate Comparison Summary: The Big Picture! 🖼️</h4>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/memory/images/Figure_5.png" alt="Hit Rate Summary Across Cache Sizes">

            <h3>🎯 Key Observations: What Did the Data Tell Us?</h3>
            <ul>
                <li>🌟 When cache sizes were <strong>super tight</strong> (like at size 64), our <strong>ML model actually outperformed LRU!</strong> (e.g., a 48% hit rate vs. 41%). Go ML!</li>
                <li>📉 As the cache got bigger, the performance gap <strong>narrowed, and sometimes even reversed</strong>.</li>
                <li>🤷 With <strong>plenty of cache space</strong>, traditional policies like FIFO and even Random started to catch up or even edge out the ML model.</li>
            </ul>

            <h3>💡 Takeaways (From an OS Builder's Perspective):</h3>
            <ul>
                <li>For <strong>general-purpose page caches</strong> in most operating systems, ML might not provide consistent enough gains to justify the added:
                  <ul>
                      <li>🤯 Complexity (more code, more things to go wrong).</li>
                      <li>🐢 Latency risks (ML predictions take time).</li>
                      <li>🔧 Maintenance cost (models need love too!).</li>
                  </ul>
                </li>
                <li>ML strategies seem to <strong>shine brightest in constrained environments</strong> ✨ where you have:
                  <ul>
                      <li>🔄 Predictable access patterns.</li>
                      <li>💰 Tight cache budgets (every hit counts!).</li>
                  </ul>
                </li>
                <li>In <strong>specialized layers</strong> (like CDN edges, VM hypervisors, or database page buffers), the trade-offs can make more sense. In fact, <strong>production ML-augmented policies are already out there in the wild!</strong> 🏞️</li>
            </ul>

            <h3>🚧 Limitations: Keeping It Real</h3>
            <ul>
                <li>This experiment used <strong>synthetic (made-up) workloads</strong> and models trained <strong>offline</strong> (not learning in real-time).</li>
                <li>The memory access trace was <strong>intentionally a bit harsh</strong>, with a low reuse rate to really push the policies.</li>
                <li>In the dynamic, ever-changing real world, <strong>"model drift"</strong> could be an issue – an ML model's predictions might become less accurate over time and even hurt performance. Yikes!</li>
            </ul>

            <h3>💭 Final Thought on Memory and ML:</h3>
            <blockquote>A model trained on yesterday’s access pattern can become obsolete the moment the user opens a different app. 🤷‍♀️<br>Without a dominant, predictable reuse pattern, ML rarely beats a robust, well-tuned LRU. Simpler is often better!</blockquote>
        </section>

        <section id="jordyos">
            <h2>✨ jordyOS: My Adventure in Building an OS! (Work In Progress 🚧)</h2>

            <p>Meet <code>jordyOS</code>! This is my very own minimal, bootable hobbyist operating system, built from the ground up. 🌱 It's a passion project featuring a command-line shell, a handy calculator app, and even a text editor that works with in-memory files!</p>

            <p>It’s crafted with love ❤️ using <strong>x86 Assembly</strong> and <strong>C</strong>, and brought to life with an i686-elf cross-compiler toolchain. When you boot it up, jordyOS starts in <strong>16-bit real mode</strong> (thanks to the bootloader), then bravely switches to <strong>32-bit protected mode</strong> to run its multitasking kernel. How cool is that?!</p>

            <hr>

            <h3>🗺️ High-Level System Design: The Blueprint</h3>
            <img src="https://raw.githubusercontent.com/duongddinh/OS-research-lab/refs/heads/main/jordyOS/images/IMG_5794.png" alt="jordyOS System Design Diagram - A map of how it all fits together!">

            <ul>
                <li><strong>System Name:</strong> jordyOS (Catchy, right? 😉)</li>
                <li><strong>Type:</strong> A 32-bit x86 protected-mode kernel.</li>
                <li><strong>Architecture:</strong> It uses cooperative multitasking (apps have to play nice and share!) and has an in-memory file system (files live in RAM for now).</li>
            </ul>

            <hr>

            <h3>🚀 Boot Process: From Power-On to Kernel Magic!</h3>
            <ol>
                <li>System powers on! BIOS wakes up in 16-bit real mode. ☀️</li>
                <li>BIOS loads the first 512 bytes (our awesome bootloader!) into memory at address <code>0x7C00</code> and jumps to it. We're off!</li>
                <li>The bootloader then:
                  <ul>
                      <li>Sets up important things like segments and the stack. 🛠️</li>
                      <li>Loads the main kernel code (starting from sector 2 on the disk) into memory at address <code>0x0800</code> using a BIOS interrupt (<code>13h</code>).</li>
                      <li>Takes a leap of faith! (A "far jump") to <code>0x0000:0800</code> to start running the kernel code.</li>
                  </ul>
                </li>
            </ol>

            <h3>🛡️ Protected Mode Setup: Entering the 32-bit Realm!</h3>
            <ol>
                <li>The kernel initially starts in real mode (at <code>0x0800</code>).</li>
                <li>First things first: Disable interrupts (<code>CLI</code>) – "Quiet please, important stuff happening!" 🤫</li>
                <li>Load the Global Descriptor Table (GDT). This table tells the CPU about our memory segments:
                    <ul>
                        <li>Entry 0: Null (standard practice).</li>
                        <li>Entry 1: A 32-bit code segment (selector <code>0x08</code>). This is where our instructions live!</li>
                        <li>Entry 2: A 32-bit data/stack segment (selector <code>0x10</code>). For variables and function calls.</li>
                    </ul>
                </li>
                <li>Set the PE (Protection Enable) bit in the <code>CR0</code> control register. This is the magic switch! ✨</li>
                <li>Execute another "far jump" to <code>0x08:protected_start</code>. We are now officially in 32-bit protected mode! Woohoo! 🎉</li>
            </ol>

            <h3>🏁 Kernel Initialization: Getting Ready to Rock!</h3>
            <ol>
                <li>Set up segment registers like <code>DS</code>, <code>SS</code>, etc., to point to our data segment (<code>0x10</code>).</li>
                <li>Set the stack pointer (<code>ESP</code>) to <code>0x9FC00</code> – this is where our kernel's stack will live.</li>
                <li>Call <code>kmain()</code>! Now we're running C code in glorious 32-bit mode. 😊</li>
            </ol>

            <h3>🎬 <code>kmain()</code> Performs: The Main Act!</h3>
            <ol>
                <li>Initializes the in-memory file system (<code>fs[]</code>). Let there be files (in RAM)! 💾</li>
                <li>Prints a friendly welcome message. 👋</li>
                <li>Creates the main shell task using <code>task_create(shell, sh_stack, size)</code>. This is our command line!</li>
                <li>Calls <code>ctx_switch()</code> to jump into the shell task and let the user take over.</li>
            </ol>

            <h3>🔄 Task Management & Context Switching: Juggling Apps!</h3>
            <ul>
                <li>Each app (task) gets its own little static stack and an entry function (where it starts).</li>
                <li><code>task_create()</code> cleverly sets up a "fake" stack frame for new tasks, making them look like they were just interrupted.</li>
                <li><code>ctx_switch.asm</code> (our assembly hero!) handles the actual switch:
                    <ul>
                        <li>Saves the current task's important registers (<code>EBP</code>, <code>EBX</code>, <code>ESI</code>, <code>EDI</code>) and its stack pointer (<code>ESP</code>).</li>
                        <li>Loads the new task's saved stack pointer.</li>
                        <li>Pops the new task's saved registers back into place.</li>
                        <li>A simple <code>RET</code> instruction then "returns" right into the new task, as if it was just called! Magic! 🪄</li>
                    </ul>
                </li>
            </ul>

            <h3>🤝 Scheduler (<code>yield</code>): Playing Fair (Cooperatively!)</h3>
            <ul>
                <li>It's a simple Round-Robin, cooperative scheduler. "Cooperative" means tasks have to voluntarily give up control.</li>
                <li>It just picks the next task in the <code>tasks[]</code> array that's ready to run.</li>
                <li>If it finds one, it updates the <code>cur</code> index and calls <code>ctx_switch()</code> to make the switch.</li>
                <li>Tasks need to be good citizens and call <code>sys_yield()</code> to let other tasks have a turn! 🙏</li>
            </ul>

            <h3>🐚 Shell Task (<code>sh></code>): Your Command Center!</h3>
            <ul>
                <li>Displays the familiar <code>sh></code> prompt.</li>
                <li>Listens for your commands, like:
                    <ul>
                        <li><code>calc</code> → launches the calculator app! 🧮</li>
                        <li><code>edit</code> → launches the text editor app! 📝</li>
                        <li><code>help</code>, <code>clear</code>, and other useful bits.</li>
                    </ul>
                </li>
                <li>Each app is started using <code>task_create()</code> and gets its very own stack.</li>
            </ul>

            <h3>🧩 Applications & Features: What Can jordyOS Do?</h3>

            <h4>🌟 Features Overview</h4>
            <ul>
                <li><strong>Bootloader (<code>bootloader.asm</code>)</strong>: The little engine that could! Sets up real mode, loads the kernel, and bravely transitions to 32-bit protected mode.</li>
                <li><strong>Kernel (<code>kernel.c</code>, <code>kernel_entry.asm</code>, <code>ctx_switch.asm</code>)</strong>: The heart of jordyOS!
                    <ul>
                        <li>📺 VGA Text Mode Output: Puts characters on the screen!</li>
                        <li>⌨️ Polling Keyboard Input: Reads your keystrokes (one by one, patiently).</li>
                        <li>👯 Cooperative Multitasking: A simple scheduler lets multiple apps (tasks) run.</li>
                        <li>📞 System Calls: An API for apps to talk to the kernel for things like:
                            <ul>
                                <li>Console I/O (<code>sys_write</code>, <code>sys_getc</code>).</li>
                                <li>Task management (<code>sys_yield</code>, <code>sys_exit_task</code>).</li>
                                <li>Screen manipulation (<code>sys_clear_screen</code>).</li>
                                <li>In-memory file operations (<code>sys_list_files</code>, <code>sys_read_file</code>, etc.).</li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li><strong>Shell (<code>sh></code>)</strong>: Your friendly command-line interface after booting. It parses your input to launch apps or run built-in commands like <code>calc</code>, <code>edit</code>, <code>clear</code>, and <code>help</code>.</li>
                <li><strong>Applications</strong>:
                    <ul>
                        <li><strong><code>app_calc</code> (Calculator)</strong> 🧮:
                            <ul>
                                <li>Interactive command-line (<code>calc></code>).</li>
                                <li>Performs basic math: <code>add</code>, <code>sub</code>, <code>mul</code>, <code>div</code>.</li>
                                <li>Type <code>exit</code> or <code>quit</code> to go back to the main shell.</li>
                            </ul>
                        </li>
                        <li><strong><code>app_edit</code> (Text Editor)</strong> 📝:
                            <ul>
                                <li>Command-driven interface (<code>edit#</code> or <code>edit [filename]#</code>).</li>
                                <li><strong>In-Memory File System Fun</strong>:
                                    <ul>
                                        <li><code>new &lt;filename&gt;</code>: Create a new text file (in memory).</li>
                                        <li><code>open &lt;filename&gt;</code>: Load an existing in-memory file.</li>
                                        <li><code>save [filename]</code>: Save your masterpiece to an in-memory file.</li>
                                        <li><code>list</code>: See all your in-memory files.</li>
                                        <li><code>delete &lt;filename&gt;</code>: Remove an in-memory file.</li>
                                    </ul>
                                </li>
                                <li><strong>Text Input Mode</strong>: Type <code>edit</code> (within <code>app_edit</code>) to add or change text. Press <code>ESC</code> to finish.</li>
                                <li><code>quit</code>: Exits the editor and returns to the main shell.</li>
                            </ul>
                        </li>
                    </ul>
                </li>
            </ul>

            <h4>💾 In-Memory File System: Files in RAM!</h4>
            <ul>
                <li>Uses a global array called <code>fs[]</code> which holds file structures.</li>
                <li>Each file has a name, a buffer for its data, its size, and an <code>in_use</code> flag.</li>
                <li>Accessed using system calls like <code>sys_write_file()</code>, <code>sys_read_file()</code>, etc.</li>
                <li>🚨 Important: No disk persistence! Files are stored only in RAM, so they vanish when you power off. (Future project, maybe? 😉)</li>
            </ul>

            <h3>🧠 Memory Model: Keeping It Simple (For Now!)</h3>
            <ul>
                <li>Flat 32-bit addressing – the whole (4GB) world is your oyster!</li>
                <li>No paging or virtual memory... yet! That's a whole other adventure.</li>
                <li>Each task gets its own separate stack. No stepping on toes!</li>
                <li>Code and data are shared globally. No strict user/kernel separation for now. (Simplicity first!)</li>
            </ul>

            <h3>⌨️ Example Usage: A Little Demo!</h3>
            <pre><code>jordyOS multitask w/ In-Memory FS 🌍

sh> help
Available commands:
  calc    - Run the calculator app 🧮
  edit    - Run the text editor app 📝
  clear   - Clear the screen ✨
  help    - Show this help message ❓

sh> calc
Calculator App. Type 'exit' or 'quit' to close.
calc> add 10 5
15
calc> mul 3 7
21
calc> exit
Exiting calculator... 👋

sh> edit
Editor v0.4 (In-Memory FS)
Commands: list, new &lt;fn&gt;, open &lt;fn&gt;, edit, save [fn], delete &lt;fn&gt;, quit
edit# new myfile.txt
New file 'myfile.txt' in buffer. Use 'edit', then 'save'.
edit [myfile.txt]# edit
--- Text Edit Mode (Press ESC to finish) ---
Hello world from jordyOS! 👋
This is a test file. 🥳
--- Exiting Text Edit Mode ---
edit [myfile.txt]# save
File 'myfile.txt' saved (36 bytes). ✅
edit [myfile.txt]# list
Files:
myfile.txt
edit [myfile.txt]# quit
Exiting editor... 👋

sh> clear
✨ Screen Cleared! ✨
</code></pre>

            <h3>🛠️ Build and Run: Want to Try It Yourself?</h3>
            <p>(These instructions are typically for macOS with Homebrew)</p>

            <h4>Install Toolchain (if you haven't already)</h4>
            <pre><code># Get ready for some compiling! 🧑‍💻
brew install cdrkit
brew install cdrtools
brew install i686-elf-binutils i686-elf-gcc
brew install nasm qemu</code></pre>

            <h4>Build and Run the OS</h4>
            <pre><code># Let's do this!
make      # Compile everything
make run  # Fire up QEMU and boot jordyOS! 🚀</code></pre>
        </section>
    </div> <footer>
        <p>Crafted with 💻 and ☕ by duongddinh. Project source code available on <a href="https://github.com/duongddinh/OS-research-lab">GitHub</a>!</p>
        <p>This little corner of the web is served with ❤️ via GitHub Pages from the /docs directory.</p>
    </footer>

</body>
</html>
